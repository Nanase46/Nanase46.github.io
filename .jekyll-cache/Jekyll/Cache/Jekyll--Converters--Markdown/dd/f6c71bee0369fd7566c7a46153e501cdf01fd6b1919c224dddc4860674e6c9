I"K,<p>ELK-生产案例项目分析及实战</p>

<h1 id="1-需求分析">1. 需求分析</h1>

<h2 id="确认需要收集的日志类型及使用的相关插件">确认需要收集的日志类型及使用的相关插件</h2>

<ul>
  <li>系统日志： /var/log/* （可以使用 input 的 syslog 插件）</li>
  <li>访问日志： Apache/Nginx/Tomcat 等的访问日志（ 使用 input 的 file/json 等插件，filter 的 grok 插件）</li>
  <li>错误日志： error log、Java 日志 （使用访问日志类似的插件，Java 的日志需要使用 codec 多行插件）</li>
  <li>运行日志： 程序自己生成的 （使用 input 的 file/json 等插件）</li>
  <li>网络日志： 防火墙、交换机、路由器等的日志 （可以使用 input 的 syslog 插件）</li>
</ul>

<h1 id="2-日志标准化">2. 日志标准化</h1>

<h2 id="21-日志放置目录及命名规范">2.1 日志放置目录及命名规范</h2>

<p>规范日志放置目录和命名 ，以下是一个示例参考：</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="o">[</span>root@linux-node1 logs]# tree /data/logs
/data/logs
├── access-log	<span class="c"># 访问日志目录</span>
├── error-log	<span class="c"># 错误日志目录</span>
└── runtime-log	<span class="c"># 运行日志目录</span>

</code></pre></div></div>

<h2 id="22-日志切割">2.2 日志切割</h2>

<p>对于不同程序，有的程序可以自定义日志切割，有的可能需要自己编写脚本来进行日志切割。<br />
日志文件切割时间可以按天、按小时等，这个需要根据实际业务的日志情况来确定。</p>

<h2 id="23-日志接入格式标准">2.3 日志接入格式标准</h2>

<p>我们可以规定，如果要接入 ELK 日志系统，程序日志格式应该是 JSON 格式，方便日志的统一接收。<br />
这个和研发去协商，为了实现 DevOps，研发和运维应该相互配合，如果日志格式不是 JSON，我们可以不接收。</p>

<h2 id="24-原始日志文件删除和归档策略">2.4 原始日志文件删除和归档策略</h2>

<p>比如可以将本地原始日志文件 rsync 到一个共享存储文件系统后，然后删除本地最近 7 天前的日志文件。
这个也是根据具体业务的日志情况来制定。<br />
如果业务一天能产生海量日志，那么可能就要删除最近一天前的日志。</p>

<h1 id="3-工具化">3. 工具化</h1>

<p>如何使用 Logstash 等 Agent 工具进行日志收集。
需要规划好方案和画好架构图。</p>

<p>参考官网架构图<br />
<img src="https://www.elastic.co/guide/en/logstash/current/static/images/deploy_6.png" alt="Multiple Connections for Logstash High Availability" /></p>

<h1 id="4-实施">4. 实施</h1>

<p>实施是基于我们在前面一系列文章的配置。</p>

<p>按照架构图安装 ELK 相关组件。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c"># 在 192.168.56.11 上的 Logstash 配置文件 shipper.conf，内容如下：</span>

<span class="o">[</span>root@linux-node1 conf.d]# <span class="nb">cat </span>shipper.conf
input <span class="o">{</span>
  file <span class="o">{</span>
    path <span class="o">=&gt;</span> <span class="s2">"/var/log/httpd/access_log"</span>
    start_position <span class="o">=&gt;</span> <span class="s2">"beginning"</span>
    <span class="nb">type</span> <span class="o">=&gt;</span> <span class="s2">"apache-access-log"</span>
    <span class="o">}</span>
  file <span class="o">{</span>
    path <span class="o">=&gt;</span> <span class="s2">"/var/log/elasticsearch/myes.log"</span>
    <span class="nb">type</span> <span class="o">=&gt;</span> <span class="s2">"es-log"</span>
    start_position <span class="o">=&gt;</span> <span class="s2">"beginning"</span>
    codec <span class="o">=&gt;</span> multiline<span class="o">{</span>
      pattern <span class="o">=&gt;</span> <span class="s2">"^</span><span class="se">\[</span><span class="s2">"</span>
      negate <span class="o">=&gt;</span> <span class="nb">true
      </span>what <span class="o">=&gt;</span> <span class="s2">"previous"</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

output <span class="o">{</span>
  <span class="k">if</span> <span class="o">[</span><span class="nb">type</span><span class="o">]</span> <span class="o">==</span> <span class="s2">"apache-access-log"</span> <span class="o">{</span>
    redis <span class="o">{</span>
      host <span class="o">=&gt;</span> <span class="s2">"192.168.56.12"</span>
      port <span class="o">=&gt;</span> 6379
      db <span class="o">=&gt;</span> 6
      data_type <span class="o">=&gt;</span> <span class="s2">"list"</span>
      key <span class="o">=&gt;</span> <span class="s2">"apache-access-log"</span>
    <span class="o">}</span>
  <span class="o">}</span>
  <span class="k">if</span> <span class="o">[</span><span class="nb">type</span><span class="o">]</span> <span class="o">==</span> <span class="s2">"es-log"</span> <span class="o">{</span>
    redis <span class="o">{</span>
      host <span class="o">=&gt;</span> <span class="s2">"192.168.56.12"</span>
      port <span class="o">=&gt;</span> 6379
      db <span class="o">=&gt;</span> 7
      data_type <span class="o">=&gt;</span> <span class="s2">"list"</span>
      key <span class="o">=&gt;</span> <span class="s2">"es-log"</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c"># 在 192.168.56.12 上的 Logstash 配置文件 indexer.conf，内容如下：</span>

<span class="o">[</span>root@linux-node2 conf.d]# <span class="nb">cat </span>indexer.conf
input <span class="o">{</span>
  syslog <span class="o">{</span>
    <span class="nb">type</span> <span class="o">=&gt;</span> <span class="s2">"system-syslog"</span>
    port <span class="o">=&gt;</span> 514
  <span class="o">}</span>
  redis <span class="o">{</span>
    <span class="nb">type</span> <span class="o">=&gt;</span> <span class="s2">"apache-access-log"</span>
    host <span class="o">=&gt;</span> <span class="s2">"192.168.56.12"</span>
    port <span class="o">=&gt;</span> 6379
    db <span class="o">=&gt;</span> 6
    data_type <span class="o">=&gt;</span> <span class="s2">"list"</span>
    key <span class="o">=&gt;</span> <span class="s2">"apache-access-log"</span>
  <span class="o">}</span>
  redis <span class="o">{</span>
    <span class="nb">type</span> <span class="o">=&gt;</span> <span class="s2">"es-log"</span>
    host <span class="o">=&gt;</span> <span class="s2">"192.168.56.12"</span>
    port <span class="o">=&gt;</span> 6379
    db <span class="o">=&gt;</span> 7
    data_type <span class="o">=&gt;</span> <span class="s2">"list"</span>
    key <span class="o">=&gt;</span> <span class="s2">"es-log"</span>
  <span class="o">}</span>

<span class="o">}</span>

filter <span class="o">{</span>
  <span class="k">if</span> <span class="o">[</span><span class="nb">type</span><span class="o">]</span> <span class="o">==</span> <span class="s2">"apache-access-log"</span> <span class="o">{</span>
    grok <span class="o">{</span>
      match <span class="o">=&gt;</span> <span class="o">{</span> <span class="s2">"message"</span> <span class="o">=&gt;</span> <span class="s2">"%{COMBINEDAPACHELOG}"</span> <span class="o">}</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

output <span class="o">{</span>
  <span class="k">if</span> <span class="o">[</span><span class="nb">type</span><span class="o">]</span> <span class="o">==</span> <span class="s2">"apache-access-log"</span> <span class="o">{</span>
    elasticsearch <span class="o">{</span>
      hosts <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">"192.168.56.11:9200"</span><span class="o">]</span>
      index <span class="o">=&gt;</span> <span class="s2">"apache-access-log-%{+YYYY.MM.dd}"</span>
    <span class="o">}</span>
  <span class="o">}</span>
  <span class="k">if</span> <span class="o">[</span><span class="nb">type</span><span class="o">]</span> <span class="o">==</span> <span class="s2">"es-log"</span> <span class="o">{</span>
    elasticsearch <span class="o">{</span>
    hosts <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">"192.168.56.11:9200"</span><span class="o">]</span>
    index <span class="o">=&gt;</span> <span class="s2">"es-log-%{+YYYY.MM}"</span>
    <span class="o">}</span>
  <span class="o">}</span>
  <span class="k">if</span> <span class="o">[</span><span class="nb">type</span><span class="o">]</span> <span class="o">==</span> <span class="s2">"system-syslog"</span> <span class="o">{</span>
    elasticsearch <span class="o">{</span>
      hosts <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">"192.168.56.11:9200"</span><span class="o">]</span>
      index <span class="o">=&gt;</span> <span class="s2">"system-syslog-%{+YYYY.MM}"</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

</code></pre></div></div>

<blockquote>

  <p>注意：</p>
  <ol>
    <li>type 是关键字，日志文件中不能使用 type；</li>
    <li>type 最好和 key 一样，这样不容易出错。</li>
  </ol>
</blockquote>

<h1 id="5-监控">5. 监控</h1>

<ol>
  <li>对 ES 以及 Kibana 进行监控。如果服务 DOWN 了要及时处理。</li>
  <li>可以使用 Redis 的 list 作为 ELK 的消息队列。</li>
  <li>对 Redis 的 List Key 长度进行监控(llen key_name)。例如: 超过”10 万”即报警(根据实际情况以及业务情况)</li>
</ol>

<h1 id="6-扩展">6. 扩展</h1>

<ol>
  <li>开源日志分析平台：ELK、EFK、EHK</li>
  <li>数据收集处理：Flume、Heka</li>
  <li>消息队列: Redis、RabbitMQ、Kafka、Hadoop、WebHDFS</li>
</ol>

<h1 id="遇到的问题">遇到的问题</h1>

<p>1.192.168.56.11 上的 Apache 日志不能写入 Redis ，原因是 logstash init 脚本运行用户和组是 logstash ，但 httpd 目录权限如下：</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="o">[</span>root@linux-node1 conf.d]# ll /var/log/httpd/ <span class="nt">-d</span>
drwx------ 2 root root 4096 Oct  9 12:18 /var/log/httpd/

</code></pre></div></div>

<p>logstash 用户进程没权限读取 access_log，当然就无法写入 Redis。  
解决办法：<br />
可以修改 logstash init 脚本运行用户和组为 root。因为 logstash 并不监听端口，所以可以换成 root 用户。<br />
但推荐将修改 <code class="highlighter-rouge">/var/log/httpd/</code> 权限为 755。</p>

<p>2.Logstash 运行时报错</p>

<p>报错这里暂时不贴出来了。（因为里面含有的特殊符号标签会被 GitHub Pages 解析不出来）</p>

<p>初步判断 <code class="highlighter-rouge">/etc/logstash/conf.d/</code> 目录下只能有 Logstash 的 YAML 格式的配置文件，不能有其他格式的文件。<br />
我将一个日志文件放在这里了，移走后就可以正常运行。</p>

:ET